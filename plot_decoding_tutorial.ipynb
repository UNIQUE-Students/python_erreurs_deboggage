{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source : https://nilearn.github.io/auto_examples/plot_decoding_tutorial.html#sphx-glr-download-auto-examples-plot-decoding-tutorial-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A introduction tutorial to fMRI decoding\n",
    "\n",
    "Here is a simple tutorial on decoding with nilearn. It reproduces the\n",
    "Haxby 2001 study on a face vs cat discrimination task in a mask of the\n",
    "ventral stream.\n",
    "\n",
    "    * J.V. Haxby et al. \"Distributed and Overlapping Representations of Faces\n",
    "      and Objects in Ventral Temporal Cortex\", Science vol 293 (2001), p\n",
    "      2425.-2430.\n",
    "\n",
    "This tutorial is meant as an introduction to the various steps of a decoding\n",
    "analysis using Nilearn meta-estimator: :class:`nilearn.decoding.Decoder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and load the fMRI data from the Haxby study\n",
    "\n",
    "### First download the data\n",
    "\n",
    "The :func:`nilearn.datasets.fetch_haxby` function will download the\n",
    "Haxby dataset if not present on the disk, in the nilearn data directory.\n",
    "It can take a while to download about 310 Mo of data from the Internet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "# By default 2nd subject will be fetched\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "# 'func' is a list of filenames: one for each subject\n",
    "fmri_filename = haxby_dataset.func[0]\n",
    "\n",
    "# print basic information on the dataset\n",
    "print(f'First subject functional nifti images (4D) are at: {fmri_filename}')  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the fmri volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "\n",
    "# Only 3D images can be plotted, not 4D so we average over time with mean_img\n",
    "plotting.view_img(mean_img(fmri_filename), threshold=none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction: from fMRI volumes to a data matrix\n",
    "\n",
    "These are some really lovely images, but for machine learning\n",
    "we need matrices to work with the actual data. Fortunately, the\n",
    ":class:`nilearn.decoding.Decoder` object we will use later on can\n",
    "automatically transform Nifti images into matrices.\n",
    "All we have to do for now is define a mask filename.\n",
    "\n",
    "A mask of the Ventral Temporal (VT) cortex coming from the\n",
    "Haxby study is available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask_filename = haxby_dataset.mask_vt\n",
    "\n",
    "# Let's visualize it, using the subject's anatomical image as a background\n",
    "plotting.plot_roi(mask_filename, bg_img=haxby_dataset.anat, cmap='paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the behavioral labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], delimiter=',')\n",
    "print(behavioral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task was a visual-recognition task, and the labels denote the\n",
    "experimental condition: the type of object that was presented to the\n",
    "subject. This is what we are going to try to predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conditions = behavioral['labels']\n",
    "print(conditions.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict the analysis to cats and faces\n",
    "\n",
    "As we can see from the targets above, the experiment contains many\n",
    "conditions. As a consequence, the data is quite big. Not all of this data\n",
    "has an interest to us for decoding, so we will keep only :term:`fmri<fMRI>` signals\n",
    "corresponding to faces or cats. We create a mask of the samples belonging to\n",
    "the condition; this mask is then applied to the :term:`fmri<fMRI>` data to restrict the\n",
    "classification to the face vs cat discrimination.\n",
    "\n",
    "The input data will become much smaller (i.e. :term:`fmri<fMRI>` signal is shorter):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mask = conditions.isin('face', 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is in one single large 4D image, we need to use\n",
    "index_img to do the split easily.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "fmri_niimgs = index_img(fmri_filename, condition_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same mask to the targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = conditions[condition_mask].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding with Support Vector Machine\n",
    "\n",
    "As a decoder, we use a Support Vector Classifier with a linear kernel. We\n",
    "first create it using by using :class:`nilearn.decoding.Decoder`.\n",
    "\n",
    "Let's leave out the 30 last data points during training, and test the\n",
    "prediction on these 30 last points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "\n",
    "fmri_niimgs_train = index_img(fmri_niimgs, slice(0, -30))\n",
    "fmri_niimgs_test = index_img(fmri_niimgs, slice(-30, None))\n",
    "conditions_train = conditions[:-30]\n",
    "conditions_test = conditions[-30:]\n",
    "\n",
    "decoder = Decoder(estimator='SVC', mask=mask_filename, standardize=True)\n",
    "decoder.fit(conditions_train, fmri_niimgs_train)\n",
    "\n",
    "prediction = decoder.predict(fmri_niimgs_test)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = (prediction == conditions_test).sum() / len(conditions_test)\n",
    "print(f\"Prediction Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the model weights\n",
    "\n",
    "Finally, it may be useful to inspect and display the model weights.\n",
    "\n",
    "### Turning the weights into a nifti image\n",
    "\n",
    "We retrieve the SVC discriminating weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = decoder.coef\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a numpy array with only one coefficient per voxel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Nifti image of these coefficients, we only need retrieve the\n",
    "`coef_img_` in the decoder and select the class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_img = decoder.coef_img_['Face']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the SVM weights\n",
    "\n",
    "We can plot the weights, using the subject's anatomical as a background\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(\n",
    "    decoder.coef_img_['face'], bg_img=haxby_dataset.anat[0],\n",
    "    title=\"SVM weights\", dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
